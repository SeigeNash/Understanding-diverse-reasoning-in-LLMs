{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMdJ6eGxKMSP",
        "outputId": "80ac9f44-6540-46f3-f8ed-531c88e17109"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.31.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.40)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch pandas tqdm accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-05-21T11:39:01.982889Z",
          "iopub.status.busy": "2024-05-21T11:39:01.982106Z",
          "iopub.status.idle": "2024-05-21T11:39:07.106121Z",
          "shell.execute_reply": "2024-05-21T11:39:07.104959Z",
          "shell.execute_reply.started": "2024-05-21T11:39:01.982855Z"
        },
        "trusted": true,
        "id": "gba2-e3AKMSR"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import torch\n",
        "import transformers\n",
        "import accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajfdJIm7Mhgx",
        "outputId": "b418e96a-b125-414c-ff1a-138ff7f9b8f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xd2TJywzKMSR"
      },
      "outputs": [],
      "source": [
        "# os.chdir('../data')\n",
        "os.chdir('/content/drive/MyDrive/reasoning-teacher/data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T11:39:07.109090Z",
          "iopub.status.busy": "2024-05-21T11:39:07.108156Z",
          "iopub.status.idle": "2024-05-21T11:39:07.120495Z",
          "shell.execute_reply": "2024-05-21T11:39:07.119374Z",
          "shell.execute_reply.started": "2024-05-21T11:39:07.109050Z"
        },
        "trusted": true,
        "id": "sCEcFJZlKMSR"
      },
      "outputs": [],
      "source": [
        "def load_data(dataset_path):\n",
        "    try:\n",
        "        with open(dataset_path, 'r') as file:\n",
        "            data = json.load(file)\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return\n",
        "\n",
        "    return data[\"metadata\"], data[\"data\"]\n",
        "\n",
        "def load_fs_prompts(prompt_file_path, key):\n",
        "    try:\n",
        "        with open(prompt_file_path, 'r') as file:\n",
        "            prompts = json.load(file)\n",
        "        separated_qa = prompts[key]['prompt'].split('\\n')\n",
        "        if len(separated_qa)>10:\n",
        "            prompts[key]['prompt'] = '\\n'.join(separated_qa[:10])\n",
        "        return prompts[key]\n",
        "    except Exception as e:\n",
        "        print(e)\n",
        "        return\n",
        "\n",
        "def generate_prompts(dataset_name=\"addsub\",\n",
        "                    dataset_dir=\"./dataset\",\n",
        "                    prompt_file_path=\"./few_shot_cot_prompts.json\"):\n",
        "    dataset_path = os.path.join(dataset_dir,dataset_name+\".json\")\n",
        "    if not os.path.exists(dataset_path):\n",
        "        raise FileNotFoundError(\"Dataset is not available\")\n",
        "\n",
        "    metadata, data = load_data(dataset_path)\n",
        "    few_shot_prompts = load_fs_prompts(prompt_file_path, key=dataset_name)\n",
        "\n",
        "    prompts = []\n",
        "    answers = []\n",
        "    indices=[]\n",
        "    for qa in data:\n",
        "        index = qa['sample_index']\n",
        "\n",
        "        if index in few_shot_prompts[\"sample_indices\"]:\n",
        "            continue\n",
        "\n",
        "        prompt = few_shot_prompts[\"prompt\"] + \"\\nQ: \" + qa[\"question\"] + \"\\nA: \"\n",
        "        answer = qa[\"answer\"]\n",
        "\n",
        "        prompts.append(prompt)\n",
        "        answers.append(answer)\n",
        "        indices.append(index)\n",
        "\n",
        "    return prompts, answers, indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T11:39:07.122482Z",
          "iopub.status.busy": "2024-05-21T11:39:07.122141Z",
          "iopub.status.idle": "2024-05-21T11:39:07.569427Z",
          "shell.execute_reply": "2024-05-21T11:39:07.568479Z",
          "shell.execute_reply.started": "2024-05-21T11:39:07.122447Z"
        },
        "trusted": true,
        "id": "jENRldWEKMSS"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import List, Tuple, Union, Optional, Dict\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "prediction_prefix = \"The answer is\"\n",
        "\n",
        "def _extract_prediction_candidates(prediction: str, dataset_key) -> List[str]:\n",
        "    \"\"\"\n",
        "    Extracts all potential answer predictions which satisfy the dataset's answer format from the\n",
        "    prediction string\n",
        "    \"\"\"\n",
        "    if dataset_key in (\"aqua\", \"commonsense_qa\"):\n",
        "        prediction = re.findall(r'[ABCDE]', prediction)\n",
        "    elif dataset_key == \"date_understanding\":\n",
        "        prediction = re.findall(r'[ABCDEF]', prediction)\n",
        "    elif dataset_key in (\"tracking_shuffled_objects\"):\n",
        "        prediction = re.findall(r'[ABC]', prediction)\n",
        "    elif dataset_key in (\"gsm8k\", \"addsub\", \"multiarith\", \"svamp\", \"single_eq\"):\n",
        "        prediction = prediction.replace(\",\", \"\")\n",
        "        prediction = re.findall(r'-?\\d+(?:\\.\\d+)?', prediction)\n",
        "        if dataset_key in (\"addsub\", \"svamp\", \"single_eq\"):\n",
        "            prediction = [float(s) for s in prediction]\n",
        "    elif dataset_key in (\"strategy_qa\", \"coin_flip\"):\n",
        "        prediction = prediction.lower()\n",
        "        prediction = re.sub(\"\\\"|\\'|\\n|\\.|\\s|\\:|\\,\", \" \", prediction)\n",
        "        prediction = prediction.split(\" \")\n",
        "        prediction = [i for i in prediction if i in (\"yes\", \"no\")]\n",
        "    elif dataset_key == \"last_letter_concatenation\":\n",
        "        prediction = re.sub(\"\\\"|\\'|\\n|\\.|\\s\", \"\", prediction)\n",
        "        prediction = [prediction]\n",
        "    else:\n",
        "        raise ValueError(\"Invalid dataset: {}\".format(dataset_key))\n",
        "\n",
        "    return prediction\n",
        "\n",
        "def _compare_prediction_and_answer(prediction, answer, dataset_key) -> bool:\n",
        "    if dataset_key in (\"addsub\", \"svamp\", \"single_eq\"):\n",
        "        return prediction is not None and abs(prediction - answer) <= 1e-6\n",
        "    else:\n",
        "        return prediction is not None and prediction == answer\n",
        "\n",
        "def cleanse_prediction(completion: str, return_all: bool,dataset_key) -> Union[str, Tuple[str, List[str]]]:\n",
        "    if prediction_prefix is None:\n",
        "        # If no prefix, use first candidate\n",
        "        predictions = _extract_prediction_candidates(completion,dataset_key=dataset_key)\n",
        "        first = True\n",
        "    else:\n",
        "        index = completion.find(prediction_prefix)\n",
        "        if index == -1:\n",
        "            # If prefix not found, use *last* candidate\n",
        "            predictions = _extract_prediction_candidates(completion,dataset_key=dataset_key)\n",
        "            first = False\n",
        "        else:\n",
        "            # If prefix found, use *first* candidate after prefix\n",
        "            start_of_answer = index + len(prediction_prefix)\n",
        "            predictions = _extract_prediction_candidates(completion[start_of_answer:],\n",
        "                                                         dataset_key=dataset_key)\n",
        "            first = True\n",
        "\n",
        "    answer = None\n",
        "    if predictions:\n",
        "        answer = (predictions[0] if first else predictions[-1])\n",
        "\n",
        "    return (answer, predictions) if return_all else answer\n",
        "\n",
        "def cleanse_answer(answer: str,dataset_key) -> str:\n",
        "    if dataset_key in [\"gsm8k\", \"addsub\", \"multiarith\", \"svamp\", \"single_eq\"]:\n",
        "        answer = answer.replace(\",\", \"\")\n",
        "    if dataset_key == \"strategy_qa\":\n",
        "        answer = answer.lower()\n",
        "    if dataset_key in [\"addsub\", \"svamp\", \"single_eq\"]:\n",
        "        answer = float(answer)\n",
        "\n",
        "    return answer\n",
        "\n",
        "def check_answer(completion_string: str, answer: str, dataset_key) -> bool:\n",
        "    \"\"\"\n",
        "    Check if a single prediction is correct.\n",
        "    \"\"\"\n",
        "    prediction = cleanse_prediction(completion_string, return_all=False,dataset_key=dataset_key)\n",
        "    answer = cleanse_answer(answer,dataset_key)\n",
        "    return _compare_prediction_and_answer(prediction, answer,dataset_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T11:39:44.708904Z",
          "iopub.status.busy": "2024-05-21T11:39:44.708248Z",
          "iopub.status.idle": "2024-05-21T11:39:44.720885Z",
          "shell.execute_reply": "2024-05-21T11:39:44.719871Z",
          "shell.execute_reply.started": "2024-05-21T11:39:44.708872Z"
        },
        "trusted": true,
        "id": "UbAl-5eOKMSS"
      },
      "outputs": [],
      "source": [
        "from transformers import T5ForConditionalGeneration, OPTForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "def get_model_inference(question, model_name, model_type):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    if model_type == \"seq2seq\":\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = T5ForConditionalGeneration.from_pretrained(model_name,\n",
        "                                                           )\n",
        "    elif model_type == \"causal\":\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        model = OPTForCausalLM.from_pretrained(model_name,\n",
        "                                               offload_folder=\".\")\n",
        "    else:\n",
        "        raise ModelNotFoundError(\"No Such model type available\")\n",
        "\n",
        "    question += \" Let's think step by step. \"\n",
        "    prompt_inpt = tokenizer(question, return_tensors=\"pt\")\n",
        "    input_ids = prompt_inpt.input_ids.to(device)\n",
        "    attention_mask = prompt_inpt.attention_mask.to(device)\n",
        "\n",
        "    outputs = model.generate(input_ids=input_ids,\n",
        "                             attention_mask=attention_mask,\n",
        "                             top_p=0.8,\n",
        "                             temperature=0.5,\n",
        "                             do_sample=True)\n",
        "    return tokenizer.decode(outputs[0])\n",
        "\n",
        "def make_completion_dataset(model_name=\"google/flan-t5-xl\",\n",
        "                            model_type=\"seq2seq\",\n",
        "                            dataset_name=\"addsub\",\n",
        "                            dataset_dir=\"./dataset\",\n",
        "                            prompt_file_path=\"./few_shot_cot_prompts.json\"):\n",
        "\n",
        "    q,a,sam_ind = generate_prompts(dataset_name=dataset_name,\n",
        "                                       dataset_dir=dataset_dir,\n",
        "                                      prompt_file_path=prompt_file_path)\n",
        "    print(len(q))\n",
        "    completion_data = []\n",
        "\n",
        "    import random\n",
        "#     sample_indices = random.sample(range(0,len(q)),200)\n",
        "\n",
        "    for i, (question,answer) in tqdm(enumerate(zip(q,a))):\n",
        "#         if i not in sample_indices:\n",
        "#             continue\n",
        "\n",
        "        model_inference = get_model_inference(question, model_name, model_type)\n",
        "        correct = check_answer(completion_string=model_inference,\n",
        "                              answer=answer,\n",
        "                              dataset_key=dataset_name)\n",
        "        single_completion = {'prompt': question,\n",
        "                             'answer': answer,\n",
        "                             'model_inference': model_inference,\n",
        "                             'correct': correct,\n",
        "                             'sample_index': sam_ind[i]}\n",
        "        completion_data.append(single_completion)\n",
        "        if i > 1:\n",
        "            break\n",
        "    return completion_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkKoMyfnKMSS"
      },
      "outputs": [],
      "source": [
        "save_path = \"./completion-data-all\"\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-18T11:57:28.822102Z",
          "iopub.status.busy": "2024-05-18T11:57:28.821281Z",
          "iopub.status.idle": "2024-05-18T11:57:28.826631Z",
          "shell.execute_reply": "2024-05-18T11:57:28.825589Z",
          "shell.execute_reply.started": "2024-05-18T11:57:28.822063Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "ec4f4501b33d4d29a79d582c0dfd4c5b",
            "5176168370074f358875050e4f16bb31",
            "613becd1c46d422c9f03292a2fab09cb",
            "7521ad45f2574df08d29a5ba07514768",
            "286a18bc99fc4ca18012221056b547b5",
            "8726e05630b948cd80d4fd695fa0d6bb",
            "fbb3bd6ee990415abcd293b802777aac",
            "f98e9f3cb9b347ee9d3f6fe01c8b0303",
            "ca949b90f1d4463581b9ddc374b4046d",
            "9d58533d21dc4bf69963d1ef5329c800",
            "78c6e9d02f364d639809c08b50e2fade"
          ]
        },
        "id": "CX10GGLmKMSS",
        "outputId": "3cb7467c-6f80-4c94-ccec-5a08f6993f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "395\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec4f4501b33d4d29a79d582c0dfd4c5b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "completion_data = make_completion_dataset(model_name=\"google/flan-t5-base\",\n",
        "                                          model_type=\"seq2seq\",\n",
        "                                          dataset_name=\"addsub\")\n",
        "with open(os.path.join(save_path,\"addsub_out.json\"), mode=\"w\") as f:\n",
        "    json.dump(completion_data,f, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-18T11:57:29.174646Z",
          "iopub.status.busy": "2024-05-18T11:57:29.174247Z",
          "iopub.status.idle": "2024-05-18T11:57:29.181598Z",
          "shell.execute_reply": "2024-05-18T11:57:29.180665Z",
          "shell.execute_reply.started": "2024-05-18T11:57:29.174597Z"
        },
        "trusted": true,
        "id": "G-fgblIkKMSS"
      },
      "outputs": [],
      "source": [
        "completion_data = make_completion_dataset(model_name=\"google/flan-t5-base\",\n",
        "                                          model_type=\"seq2seq\",\n",
        "                                          dataset_name=\"date_understanding\")\n",
        "with open(os.path.join(save_path,\"date_understanding_out.json\"), mode=\"w\") as f:\n",
        "    json.dump(completion_data,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "TCcFRaVDKMSS"
      },
      "outputs": [],
      "source": [
        "completion_data = make_completion_dataset(model_name=\"google/flan-t5-base\",\n",
        "                                          model_type=\"seq2seq\",\n",
        "                                          dataset_name=\"coin_flip\")\n",
        "with open(os.path.join(save_path,\"coin_flip_out.json\"), mode=\"w\") as f:\n",
        "    json.dump(completion_data,f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "wMTD8eNSKMST"
      },
      "outputs": [],
      "source": [
        "completion_data = make_completion_dataset(model_name=\"google/flan-t5-base\",\n",
        "                                          model_type=\"seq2seq\",\n",
        "                                          dataset_name=\"commonsense_qa\")\n",
        "with open(os.path.join(save_path,\"commonsense_qa_out.json\"), mode=\"w\") as f:\n",
        "    json.dump(completion_data,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "Gw96E6czKMST"
      },
      "outputs": [],
      "source": [
        "completion_data = make_completion_dataset(model_name=\"google/flan-t5-base\",\n",
        "                                          model_type=\"seq2seq\",\n",
        "                                          dataset_name=\"last_letter_concatenation\")\n",
        "with open(os.path.join(save_path,\"last_letter_concatenation_out.json\"), mode=\"w\") as f:\n",
        "    json.dump(completion_data,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "QlpWDeKNKMST"
      },
      "outputs": [],
      "source": [
        "completion_data = make_completion_dataset(model_name=\"google/flan-t5-base\",\n",
        "                                          model_type=\"seq2seq\",\n",
        "                                          dataset_name=\"single_eq\")\n",
        "with open(os.path.join(save_path,\"single_eq_out.json\"), mode=\"w\") as f:\n",
        "    json.dump(completion_data,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-18T12:06:03.815171Z",
          "iopub.status.busy": "2024-05-18T12:06:03.814218Z",
          "iopub.status.idle": "2024-05-18T15:55:42.215399Z",
          "shell.execute_reply": "2024-05-18T15:55:42.214448Z",
          "shell.execute_reply.started": "2024-05-18T12:06:03.815131Z"
        },
        "trusted": true,
        "id": "FQ7HAICKKMST"
      },
      "outputs": [],
      "source": [
        "completion_data = make_completion_dataset(model_name=\"google/flan-t5-base\",\n",
        "                                          model_type=\"seq2seq\",\n",
        "                                          dataset_name=\"strategy_qa\")\n",
        "with open(os.path.join(save_path,\"strategy_qa_out.json\"), mode=\"w\") as f:\n",
        "    json.dump(completion_data,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fezbieHtKMST"
      },
      "outputs": [],
      "source": [
        "completion_data = make_completion_dataset(model_name=\"google/flan-t5-base\",\n",
        "                                          model_type=\"seq2seq\",\n",
        "                                          dataset_name=\"multiarith\")\n",
        "with open(os.path.join(save_path,\"multiarith_out.json\"), mode=\"w\") as f:\n",
        "    json.dump(completion_data,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-28T03:45:59.104302Z",
          "iopub.status.busy": "2024-06-28T03:45:59.103853Z",
          "iopub.status.idle": "2024-06-28T03:45:59.139281Z",
          "shell.execute_reply": "2024-06-28T03:45:59.138076Z",
          "shell.execute_reply.started": "2024-06-28T03:45:59.104264Z"
        },
        "trusted": true,
        "id": "mSExm8lGKMST"
      },
      "outputs": [],
      "source": [
        "completion_data = make_completion_dataset(model_name=\"google/flan-t5-base\",\n",
        "                                          model_type=\"seq2seq\",\n",
        "                                          dataset_name=\"svamp\")\n",
        "with open(os.path.join(save_path,\"svamp_out.json\"), mode=\"w\") as f:\n",
        "    json.dump(completion_data,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhrMlqw8KMST"
      },
      "outputs": [],
      "source": [
        "completion_data = make_completion_dataset(model_name=\"google/flan-t5-base\",\n",
        "                                          model_type=\"seq2seq\",\n",
        "                                          dataset_name=\"tracking_shffled_objects\")\n",
        "with open(os.path.join(save_path,\"tracking_shhuffled_objects_out.json\"), mode=\"w\") as f:\n",
        "    json.dump(completion_data,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-18T11:57:52.469260Z",
          "iopub.status.busy": "2024-05-18T11:57:52.468943Z",
          "iopub.status.idle": "2024-05-18T11:57:52.475774Z",
          "shell.execute_reply": "2024-05-18T11:57:52.474757Z",
          "shell.execute_reply.started": "2024-05-18T11:57:52.469237Z"
        },
        "trusted": true,
        "id": "9JgYN4IYKMST",
        "outputId": "a4731b11-54ef-429a-c26a-ccf42fd02fea"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'prompt': 'Q: Do hamsters provide food for any animals?\\nA: Hamsters are prey animals. Prey are food for predators. Thus, hamsters provide food for some animals. The answer is yes.\\nQ: Could Brooke Shields succeed at University of Pennsylvania?\\nA: Brooke Shields went to Princeton University. Princeton University is about as academically rigorous as the University of Pennsylvania. Thus, Brooke Shields could also succeed at the University of Pennsylvania. The answer is yes.\\nQ: Yes or no: Hydrogen’s atomic number squared exceeds number of Spice Girls?\\nA: Hydrogen has an atomic number of 1. 1 squared is 1. There are 5 Spice Girls. Thus, Hydrogen’s atomic number squared is less than 5. The answer is no.\\nQ: Yes or no: Is it common to see frost during some college commencements?\\nA: College commencement ceremonies can happen in December, May, and June. December is in the winter, so there can be frost. Thus, there could be frost at some commencements. The answer is yes.\\nQ: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?\\nA: The War in Vietnam was 6 months. The gestation period for a llama is 11 months, which is more than 6 months. Thus, a llama could not give birth twice during the War in Vietnam. The answer is no.\\nQ: Are all limbs required for jujutsu?\\nA: ',\n",
              "  'answer': 'No',\n",
              "  'model_inference': '<pad> No. Jujutsu is a martial art with all limbs required. The answer is no. <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk>',\n",
              "  'correct': True,\n",
              "  'sample_index': 4},\n",
              " {'prompt': 'Q: Do hamsters provide food for any animals?\\nA: Hamsters are prey animals. Prey are food for predators. Thus, hamsters provide food for some animals. The answer is yes.\\nQ: Could Brooke Shields succeed at University of Pennsylvania?\\nA: Brooke Shields went to Princeton University. Princeton University is about as academically rigorous as the University of Pennsylvania. Thus, Brooke Shields could also succeed at the University of Pennsylvania. The answer is yes.\\nQ: Yes or no: Hydrogen’s atomic number squared exceeds number of Spice Girls?\\nA: Hydrogen has an atomic number of 1. 1 squared is 1. There are 5 Spice Girls. Thus, Hydrogen’s atomic number squared is less than 5. The answer is no.\\nQ: Yes or no: Is it common to see frost during some college commencements?\\nA: College commencement ceremonies can happen in December, May, and June. December is in the winter, so there can be frost. Thus, there could be frost at some commencements. The answer is yes.\\nQ: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?\\nA: The War in Vietnam was 6 months. The gestation period for a llama is 11 months, which is more than 6 months. Thus, a llama could not give birth twice during the War in Vietnam. The answer is no.\\nQ: Does Linus Torvalds make money off of DirectX?\\nA: ',\n",
              "  'answer': 'No',\n",
              "  'model_inference': '<pad> No. Linus Torvalds is a Swedish rapper. DirectX is a computer program. The answer is no. <unk>rnus torvalds is a Swedish rapper. The answer is no. <unk>rnus torvalds is a Swedish rapper.</s>',\n",
              "  'correct': True,\n",
              "  'sample_index': 6},\n",
              " {'prompt': 'Q: Do hamsters provide food for any animals?\\nA: Hamsters are prey animals. Prey are food for predators. Thus, hamsters provide food for some animals. The answer is yes.\\nQ: Could Brooke Shields succeed at University of Pennsylvania?\\nA: Brooke Shields went to Princeton University. Princeton University is about as academically rigorous as the University of Pennsylvania. Thus, Brooke Shields could also succeed at the University of Pennsylvania. The answer is yes.\\nQ: Yes or no: Hydrogen’s atomic number squared exceeds number of Spice Girls?\\nA: Hydrogen has an atomic number of 1. 1 squared is 1. There are 5 Spice Girls. Thus, Hydrogen’s atomic number squared is less than 5. The answer is no.\\nQ: Yes or no: Is it common to see frost during some college commencements?\\nA: College commencement ceremonies can happen in December, May, and June. December is in the winter, so there can be frost. Thus, there could be frost at some commencements. The answer is yes.\\nQ: Yes or no: Could a llama birth twice during War in Vietnam (1945-46)?\\nA: The War in Vietnam was 6 months. The gestation period for a llama is 11 months, which is more than 6 months. Thus, a llama could not give birth twice during the War in Vietnam. The answer is no.\\nQ: Could a silverfish reach the top of the Empire State Building?\\nA: ',\n",
              "  'answer': 'No',\n",
              "  'model_inference': '<pad> No. The Empire State Building is 3,900 feet tall. The answer is no.. The answer is no.....................................................',\n",
              "  'correct': True,\n",
              "  'sample_index': 8}]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "completion_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "Xfcve9tEKMST"
      },
      "outputs": [],
      "source": [
        "# completion_data = make_completion_dataset(model_name=\"google/flan-t5-xl\",\n",
        "#                                           model_type=\"seq2seq\",\n",
        "#                                           dataset_name=\"svamp\")\n",
        "# with open(\"/kaggle/working/svamp_out.json\", mode=\"w\") as f:\n",
        "#     json.dump(completion_data,f,indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true,
        "id": "2t-1c1guKMST"
      },
      "outputs": [],
      "source": [
        "completion_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZio2Mj_KMST"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4836395,
          "sourceId": 8171736,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4836482,
          "sourceId": 8171851,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ec4f4501b33d4d29a79d582c0dfd4c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5176168370074f358875050e4f16bb31",
              "IPY_MODEL_613becd1c46d422c9f03292a2fab09cb",
              "IPY_MODEL_7521ad45f2574df08d29a5ba07514768"
            ],
            "layout": "IPY_MODEL_286a18bc99fc4ca18012221056b547b5"
          }
        },
        "5176168370074f358875050e4f16bb31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8726e05630b948cd80d4fd695fa0d6bb",
            "placeholder": "​",
            "style": "IPY_MODEL_fbb3bd6ee990415abcd293b802777aac",
            "value": ""
          }
        },
        "613becd1c46d422c9f03292a2fab09cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f98e9f3cb9b347ee9d3f6fe01c8b0303",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ca949b90f1d4463581b9ddc374b4046d",
            "value": 1
          }
        },
        "7521ad45f2574df08d29a5ba07514768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d58533d21dc4bf69963d1ef5329c800",
            "placeholder": "​",
            "style": "IPY_MODEL_78c6e9d02f364d639809c08b50e2fade",
            "value": " 2/? [00:30&lt;00:00, 10.45s/it]"
          }
        },
        "286a18bc99fc4ca18012221056b547b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8726e05630b948cd80d4fd695fa0d6bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbb3bd6ee990415abcd293b802777aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f98e9f3cb9b347ee9d3f6fe01c8b0303": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ca949b90f1d4463581b9ddc374b4046d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d58533d21dc4bf69963d1ef5329c800": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78c6e9d02f364d639809c08b50e2fade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}